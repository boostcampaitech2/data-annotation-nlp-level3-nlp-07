# Boostcamp Machine Reading Comprehension Competition
## **Table of contents**

1. [Introduction](#1-introduction)
2. [Project Outline](#2-project-outline)
3. [Solution](#3-solution)
4. [How to Use](#4-how-to-use)

# 1. Introduction  
<br/>
<p align="center">
   <img src="https://user-images.githubusercontent.com/62708568/140640556-b2a0406c-09cd-48be-ae37-4c65e206b693.JPG" style="width:1000px;"/>
</p>

<br/>


## ğŸ¶ TEAM : ì¡°ì§€KLUEë‹ˆ
### ğŸ”… Members  

ê¹€ë³´ì„±|ê¹€ì§€í›„|ê¹€í˜œìˆ˜|ë°•ì´ì‚­|ì´ë‹¤ê³¤|ì „ë¯¸ì›|ì •ë‘í•´
:-:|:-:|:-:|:-:|:-:|:-:|:-:
![image1][image1]|![image2][image2]|![image3][image3]|![image4][image4]|![image5][image5]|![image6][image6]|![image7][image7]
[Github](https://github.com/Barleysack)|[Github](https://github.com/JIHOO97)|[Github](https://github.com/vgptnv)|[Github](https://github.com/Tentoto)|[Github](https://github.com/DagonLee)|[Github](https://github.com/ekdub92)|[Github](https://github.com/Doohae)


### ğŸ”… Contribution

`ê¹€ë³´ì„±`Â  Entity Tagging â€¢ Relation Tagging â€¢ RE Tool ê°œì„ 

`ê¹€ì§€í›„`   Entity Tagging â€¢ Relation Tagging

`ê¹€í˜œìˆ˜`Â  Entity Tag Set â€¢ Relation Tagging â€¢ Annotate

`ë°•ì´ì‚­`Â  Entity ì •ì˜ â€¢ Relation ì •ì˜ â€¢ Random entity pair ì¶”ì¶œ

`ì´ë‹¤ê³¤`Â  Entity Tagging â€¢ Relation Tagging

`ì „ë¯¸ì›`Â  Data Preprocessing â€¢ Entity Tagging â€¢ Relation Tagging â€¢ Data Pilot

`ì •ë‘í•´`Â  RE program ê°œë°œ â€¢ í•œêµ­ì–´ ë¬¸ë²• íŠ¹ì„± ì •ë¦¬ â€¢ Entity Tagging â€¢ Relation Tagging â€¢ Random Entity Pair ì¶”ì¶œ

[image1]: https://avatars.githubusercontent.com/u/56079922?v=4
[image2]: https://avatars.githubusercontent.com/u/57887761?v=4
[image3]: https://avatars.githubusercontent.com/u/62708568?v=4
[image4]: https://avatars.githubusercontent.com/u/80071163?v=4
[image5]: https://avatars.githubusercontent.com/u/43575986?v=4
[image6]: https://avatars.githubusercontent.com/u/42200769?v=4
[image7]: https://avatars.githubusercontent.com/u/80743307?v=4

<br/>


# 2. Project Outline

- Task : í•œêµ­ì–´ Relation Extraction taskë¥¼ ìœ„í•œ ë°ì´í„° ì½”í¼ìŠ¤ êµ¬ì¶•
- Date : 2021.11.08 - 2021.11.19 (2 weeks)
- Description : í•œêµ­ì–´Â ë° ë‹¤ë¥¸ ì–¸ì–´ì—ì„œì˜ ìì—°ì–´ì²˜ë¦¬ ë°ì´í„°ì…‹ì˜ ìœ í˜• ë° í¬ë§·ì´ ì–´ë– í•œì§€, ê·¸ë¦¬ê³  ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ëŠ” ì¼ë°˜ì ì¸ í”„ë¡œì„¸ìŠ¤ê°€ ë¬´ì—‡ì¸ì§€ í•™ìŠµí•˜ê³  ìœ„í‚¤í”¼ë””ì•„ ì›ì‹œ ë§ë­‰ì¹˜ë¥¼ í™œìš©í•˜ì—¬ ì§ì ‘Â ê´€ê³„ ì¶”ì¶œ íƒœìŠ¤í¬ì— ì“°ì´ëŠ” ì£¼ì„ ì½”í¼ìŠ¤ êµ¬ì¶•


### ğŸ† Final Score
<br/>
<p align="center">
   <img src="https://user-images.githubusercontent.com/62708568/140643039-32a5da8a-0643-48f6-b272-4fbb6d58c57b.png" style="width:1000px;"/>
</p>
<br/>
ëŒ€íšŒ ì‚¬ì´íŠ¸ : [AI stage](https://stages.ai/competitions/79/overview/description)

## **Hardware**

AI stageì—ì„œ ì œê³µí•œ server, GPU

- GPU: V100

# 3. Solution

### KEY POINT

- ODQA Task (Open Domain Question Answering) : Retrieval + Reader ëª¨ë¸ì´ ê²°í•©ëœ Hybrid model
- DPR ë…¼ë¬¸ì˜ negative sample ì¶”ê°€ í•™ìŠµ + Dense Retriever ëª¨ë¸ì„ ì°¨ìš©í•´ elasticsearchì™€ ê²°í•©í•˜ì—¬ retriever ëª¨ë¸ êµ¬í˜„
- GPT-2ë¥¼ í™œìš©í•´ wiki ë°ì´í„°ì˜ contextì— pairedëœ ì§ˆì˜ë¥¼ ìƒì„±í•´ Retrieval Dense Encoder ëª¨ë¸ í•™ìŠµ
- Data Augmentationì„ í†µí•´ ì§€ë¬¸ì˜ ê¸¸ì´ë¥¼ ëŠ˜ë¦° í›„ í•™ìŠµ ë°ì´í„°ë¡œ ì´ìš©
- ëŒ€ëŸ‰ì˜ í•œêµ­ì–´ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµ ë˜ì–´ ìˆëŠ” `klue/roberta-large` ëª¨ë¸ì„ ë¦¬ë” ëª¨ë¸ë¡œ ì‚¬ìš©

### Checklist

- [x]  EDA
- [x]  Data Preprocessing(`special character removal`, `getting answer spans' start position with special character tokens`)
- [x]  Data Augmentation(`Back translation`, `Question generation`)
- [x]  Data Postprocessing
- [x]  Experimental Logging (`WandB`)
- [x]  Retrieval (`dense -- FAISS,using simple dual-encoders`, `sparse -- TF-IDF,BM25,Elastic search`, `Dense+Sparse -- using a linear combination of dense and sparse scores as the new raking function`)
- [x]  Custom Model Architecture(`Roberta with BiLSTM`, `Roberta with Autoencoder`)
- [x]  Re-ranker ( combining the reader score with the retriever score via linear combination `inspired by BERTserini`)
- [x]  Ensemble
- [ ]  Don't stop Pretraining (additional MLM Task, TAPT + DAPT)
- [ ]  K-fold cross validation
- [ ]  Shorten inference time when using elastic search

### Experiments

| Tried Experiments | Pipeline | Performance Improvement |
| --- | --- | --- |
| `TF-IDF` | `Retrieval` | <ul><li><center> [x] </center></li> | 
| `ElasticSearch config setting` | `Retrieval` | <ul><li> [ ] </li> | 
| `Question Generation (using GPT-2)` | `Retrieval` | <ul><li> [ ] </li> |
| `hard negative (using BM25 + ElasticSearch)` | `Retrieval` | <ul><li> [x] </li> |
| `DPR implementation` | `Retrieval` | <ul><li> [x] </li> |
| `Dense+Sparse` | `Retrieval` | <ul><li> [x] </li> |
| `Roberta with Bi-LSTM` | `Reader` | <ul><li> [ ] </li> |
| `Roberta with Autoencoder` | `Reader` | <ul><li> [ ] </li> |
| `Back-Translation` | `Reader` | <ul><li> [ ] </li> |
| `Context Concat(hard negative)` | `Reader` | <ul><li> [x] </li> |
| `Retrival+Reader Re-Ranker`  | `Inference` | <ul><li> [x] </li> |
   

# 4. How to Use

## **Installation**

ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ librariesë¥¼ ë‹¤ìš´ ë°›ìŠµë‹ˆë‹¤.

`pip install -r requirements.txt`

Elasticsearch ëª¨ë“ˆ (ì¶œì²˜ : [ì„œì¤‘ì› ë©˜í† ë‹˜ ê¹ƒí—ˆë¸Œ](https://github.com/thejungwon/search-engine-tutorial))
```
apt-get update && apt-get install -y gnupg2
wget -qO - [https://artifacts.elastic.co/GPG-KEY-elasticsearch](https://artifacts.elastic.co/GPG-KEY-elasticsearch) | apt-key add -
apt-get install apt-transport-https
echo "deb [https://artifacts.elastic.co/packages/7.x/apt](https://artifacts.elastic.co/packages/7.x/apt) stable main" | tee /etc/apt/sources.list.d/elastic-7.x.list
apt-get update && apt-get install elasticsearch
service elasticsearch start
cd /usr/share/elasticsearch
bin/elasticsearch-plugin install analysis-nori
service elasticsearch restart
pip install elasticsearch
```

BM25 ëª¨ë“ˆ

`pip install rank_bm25`

Google deep_translator ëª¨ë“ˆ

`pip install -U deep-translator`

## **Dataset**

íŒŒì¼: data/train_dataset/train, data/train_dataset/validation, data/test_dataset/validation 

## **Data Analysis**

íŒŒì¼: code/notebooks/(folder)

## **Data preprocessing**

íŒŒì¼: preprocess.py, process_data.py, back_translation.py

## **Modeling**

íŒŒì¼: train.py, inference.py, golden_retriever.py, golden_serini.py, inference_serini.py

## **Ensemble**

íŒŒì¼: mixing_bowl.ipynb, mixing_bowl (1).ipynb

## Directory

```
.
â”œâ”€â”€ mrc-level2-nlp-07
|    â”œâ”€â”€ code
â”‚        â”œâ”€â”€ outputs
â”‚        â”œâ”€â”€ dense_encoder
â”‚        â”œâ”€â”€ retriever
|    â”œâ”€â”€ data
â”‚        â”œâ”€â”€ train_dataset
|            â”œâ”€â”€ train
|            â”œâ”€â”€ validation
â”‚        â”œâ”€â”€ test_dataset
|            â”œâ”€â”€ validation
|        â”œâ”€â”€ wikipedia_passages.json
```

- `code` íŒŒì¼ ì•ˆì—ëŠ” ê°ê° **data preprocessing** â€¢ **train** â€¢ **inference**ê°€ ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
- `train.py`ë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ logs, results, best_model í´ë”ì— ê²°ê³¼ë“¤ì´ ì €ì¥ë©ë‹ˆë‹¤.
- ì‚¬ìš©ìëŠ” ì „ì²´ ì½”ë“œë¥¼ ë‚´ë ¤ë°›ì€ í›„, argument ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ ê°œë³„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
