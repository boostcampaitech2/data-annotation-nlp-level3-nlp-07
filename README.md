# Boostcamp Machine Reading Comprehension Competition
## **Table of contents**

1. [Introduction](#1-introduction)
2. [Project Outline](#2-project-outline)
3. [Solution](#3-solution)
4. [How to Use](#4-how-to-use)

# 1. Introduction  
<br/>
<p align="center">
   <img src="https://user-images.githubusercontent.com/62708568/140640556-b2a0406c-09cd-48be-ae37-4c65e206b693.JPG" style="width:1000px;"/>
</p>

<br/>


## ğŸ¶ TEAM : ì¡°ì§€KLUEë‹ˆ
### ğŸ”… Members  

ê¹€ë³´ì„±|ê¹€ì§€í›„|ê¹€í˜œìˆ˜|ë°•ì´ì‚­|ì´ë‹¤ê³¤|ì „ë¯¸ì›|ì •ë‘í•´
:-:|:-:|:-:|:-:|:-:|:-:|:-:
![image1][image1]|![image2][image2]|![image3][image3]|![image4][image4]|![image5][image5]|![image6][image6]|![image7][image7]
[Github](https://github.com/Barleysack)|[Github](https://github.com/JIHOO97)|[Github](https://github.com/vgptnv)|[Github](https://github.com/Tentoto)|[Github](https://github.com/DagonLee)|[Github](https://github.com/ekdub92)|[Github](https://github.com/Doohae)


### ğŸ”… Contribution

`ê¹€ë³´ì„±`Â  Modeling â€¢ Reference searching â€¢ Paper implementation â€¢ Ensemble â€¢ github management

`ê¹€ì§€í›„`   FAISS â€¢ Reference Searching

`ê¹€í˜œìˆ˜`Â  Reference Searching â€¢ ElasticSearch config & Optimization â€¢ Data Processing â€¢ Sparse/Dense Retrieval

`ë°•ì´ì‚­`Â  Reference Searching â€¢ Github management

`ì´ë‹¤ê³¤`Â  Data Processing â€¢ Generative MRC

`ì „ë¯¸ì›`Â  Data Preprocessing â€¢ Add Elastic Search into baseline â€¢ Re-ranking MRC outputs w/ Retrieval â€¢ Ensemble

`ì •ë‘í•´`Â  Data Exploration â€¢ Baseline Abstraction â€¢ Sparse/Dense Retriever â€¢ Reader Model Searching â€¢ Data Augmentation â€¢ MRC Hyperparameter Tuning â€¢ Pre/Postprocessing

[image1]: https://avatars.githubusercontent.com/u/56079922?v=4
[image2]: https://avatars.githubusercontent.com/u/57887761?v=4
[image3]: https://avatars.githubusercontent.com/u/62708568?v=4
[image4]: https://avatars.githubusercontent.com/u/80071163?v=4
[image5]: https://avatars.githubusercontent.com/u/43575986?v=4
[image6]: https://avatars.githubusercontent.com/u/42200769?v=4
[image7]: https://avatars.githubusercontent.com/u/80743307?v=4

<br/>


# 2. Project Outline

- Task : Extractive-based MRCë¥¼ ìœ„í•œ ODQA ëª¨ë¸ êµ¬ì¶•
- Date : 2021.10.12 - 2021.11.04 (4 weeks)
- Description : **ë³¸ ODQA ëŒ€íšŒì—ì„œ ìš°ë¦¬ê°€ ë§Œë“¤ ëª¨ë¸ì€ two-stage**ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.Â **ì²« ë‹¨ê³„ëŠ” ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” "retriever"**Â ë‹¨ê³„ì´ê³ ,Â **ë‹¤ìŒìœ¼ë¡œëŠ” ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì½ê³  ì ì ˆí•œ ë‹µë³€ì„ ì°¾ê±°ë‚˜ ë§Œë“¤ì–´ì£¼ëŠ” "reader"**Â ë‹¨ê³„ì…ë‹ˆë‹¤. ë‘ ê°€ì§€ ë‹¨ê³„ë¥¼ ê°ê° êµ¬ì„±í•˜ê³  ê·¸ê²ƒë“¤ì„ ì ì ˆíˆ í†µí•©í•˜ê²Œ ë˜ë©´, ì–´ë ¤ìš´ ì§ˆë¬¸ì„ ë˜ì ¸ë„ ë‹µë³€ì„ í•´ì£¼ëŠ” ODQA ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ë¶„ë“¤ ì†ìœ¼ë¡œ ì§ì ‘ ë§Œë“¤ì–´ë³´ê²Œ ë©ë‹ˆë‹¤.
- Train : 3,952ê°œ
- Validation : 240ê°œ
- Test : 600ê°œ

### ğŸ† Final Score
<br/>
<p align="center">
   <img src="https://user-images.githubusercontent.com/62708568/140643039-32a5da8a-0643-48f6-b272-4fbb6d58c57b.png" style="width:1000px;"/>
</p>
<br/>
ëŒ€íšŒ ì‚¬ì´íŠ¸ : [AI stage](https://stages.ai/competitions/77)

## **Hardware**

AI stageì—ì„œ ì œê³µí•œ server, GPU

- GPU: V100

# 3. Solution

### KEY POINT

- ODQA Task (Open Domain Question Answering) : Retrieval + Reader ëª¨ë¸ì´ ê²°í•©ëœ Hybrid model
- DPR ë…¼ë¬¸ì˜ negative sample ì¶”ê°€ í•™ìŠµ + Dense Retriever ëª¨ë¸ì„ ì°¨ìš©í•´ elasticsearchì™€ ê²°í•©í•˜ì—¬ retriever ëª¨ë¸ êµ¬í˜„
- GPT-2ë¥¼ í™œìš©í•´ wiki ë°ì´í„°ì˜ contextì— pairedëœ ì§ˆì˜ë¥¼ ìƒì„±í•´ Retrieval Dense Encoder ëª¨ë¸ í•™ìŠµ
- Data Augmentationì„ í†µí•´ ì§€ë¬¸ì˜ ê¸¸ì´ë¥¼ ëŠ˜ë¦° í›„ í•™ìŠµ ë°ì´í„°ë¡œ ì´ìš©
- ëŒ€ëŸ‰ì˜ í•œêµ­ì–´ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµ ë˜ì–´ ìˆëŠ” `klue/roberta-large` ëª¨ë¸ì„ ë¦¬ë” ëª¨ë¸ë¡œ ì‚¬ìš©

### Checklist

- [x]  EDA
- [x]  Data Preprocessing(`special character removal`, `getting answer spans' start position with special character tokens`)
- [x]  Data Augmentation(`Back translation`, `Question generation`)
- [x]  Data Postprocessing
- [x]  Experimental Logging (`WandB`)
- [x]  Retrieval (`dense -- FAISS,using simple dual-encoders`, `sparse -- TF-IDF,BM25,Elastic search`, `Dense+Sparse -- using a linear combination of dense and sparse scores as the new raking function`)
- [x]  Custom Model Architecture(`Roberta with BiLSTM`, `Roberta with Autoencoder`)
- [x]  Re-ranker ( combining the reader score with the retriever score via linear combination `inspired by BERTserini`)
- [x]  Ensemble
- [ ]  Don't stop Pretraining (additional MLM Task, TAPT + DAPT)
- [ ]  K-fold cross validation
- [ ]  Shorten inference time when using elastic search

### Experiments

| Tried Experiments | Pipeline | Performance Improvement |
| --- | --- | --- |
| `TF-IDF` | `Retrieval` | <ul><li><center> [x] </center></li> | 
| `ElasticSearch config setting` | `Retrieval` | <ul><li> [ ] </li> | 
| `Question Generation (using GPT-2)` | `Retrieval` | <ul><li> [ ] </li> |
| `hard negative (using BM25 + ElasticSearch)` | `Retrieval` | <ul><li> [x] </li> |
| `DPR implementation` | `Retrieval` | <ul><li> [x] </li> |
| `Dense+Sparse` | `Retrieval` | <ul><li> [x] </li> |
| `Roberta with Bi-LSTM` | `Reader` | <ul><li> [ ] </li> |
| `Roberta with Autoencoder` | `Reader` | <ul><li> [ ] </li> |
| `Back-Translation` | `Reader` | <ul><li> [ ] </li> |
| `Context Concat(hard negative)` | `Reader` | <ul><li> [x] </li> |
| `Retrival+Reader Re-Ranker`  | `Inference` | <ul><li> [x] </li> |
   

# 4. How to Use

## **Installation**

ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ librariesë¥¼ ë‹¤ìš´ ë°›ìŠµë‹ˆë‹¤.

`pip install -r requirements.txt`

Elasticsearch ëª¨ë“ˆ (ì¶œì²˜ : [ì„œì¤‘ì› ë©˜í† ë‹˜ ê¹ƒí—ˆë¸Œ](https://github.com/thejungwon/search-engine-tutorial))
```
apt-get update && apt-get install -y gnupg2
wget -qO - [https://artifacts.elastic.co/GPG-KEY-elasticsearch](https://artifacts.elastic.co/GPG-KEY-elasticsearch) | apt-key add -
apt-get install apt-transport-https
echo "deb [https://artifacts.elastic.co/packages/7.x/apt](https://artifacts.elastic.co/packages/7.x/apt) stable main" | tee /etc/apt/sources.list.d/elastic-7.x.list
apt-get update && apt-get install elasticsearch
service elasticsearch start
cd /usr/share/elasticsearch
bin/elasticsearch-plugin install analysis-nori
service elasticsearch restart
pip install elasticsearch
```

BM25 ëª¨ë“ˆ

`pip install rank_bm25`

Google deep_translator ëª¨ë“ˆ

`pip install -U deep-translator`

## **Dataset**

íŒŒì¼: data/train_dataset/train, data/train_dataset/validation, data/test_dataset/validation 

## **Data Analysis**

íŒŒì¼: code/notebooks/(folder)

## **Data preprocessing**

íŒŒì¼: preprocess.py, process_data.py, back_translation.py

## **Modeling**

íŒŒì¼: train.py, inference.py, golden_retriever.py, golden_serini.py, inference_serini.py

## **Ensemble**

íŒŒì¼: mixing_bowl.ipynb, mixing_bowl (1).ipynb

## Directory

```
.
â”œâ”€â”€ mrc-level2-nlp-07
|    â”œâ”€â”€ code
â”‚        â”œâ”€â”€ outputs
â”‚        â”œâ”€â”€ dense_encoder
â”‚        â”œâ”€â”€ retriever
|    â”œâ”€â”€ data
â”‚        â”œâ”€â”€ train_dataset
|            â”œâ”€â”€ train
|            â”œâ”€â”€ validation
â”‚        â”œâ”€â”€ test_dataset
|            â”œâ”€â”€ validation
|        â”œâ”€â”€ wikipedia_passages.json
```

- `code` íŒŒì¼ ì•ˆì—ëŠ” ê°ê° **data preprocessing** â€¢ **train** â€¢ **inference**ê°€ ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
- `train.py`ë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ logs, results, best_model í´ë”ì— ê²°ê³¼ë“¤ì´ ì €ì¥ë©ë‹ˆë‹¤.
- ì‚¬ìš©ìëŠ” ì „ì²´ ì½”ë“œë¥¼ ë‚´ë ¤ë°›ì€ í›„, argument ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ ê°œë³„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
